{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as functional\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n 0.2333  0.0386 -0.1757  0.5129 -0.3680 -0.0277 -0.0404  0.0653  0.3291  0.1256\n 0.2515  0.0269 -0.2324  0.6073 -0.3457 -0.0622 -0.0633  0.0669  0.2966  0.1034\n[torch.FloatTensor of size 2x10]\n\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, width_multiplier: int, use_batchnorm=False):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.width_multiplier = width_multiplier\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 2 * width_multiplier, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(2 * width_multiplier, 4 * width_multiplier, 5, padding=2)\n",
    "        self.linear: nn.Linear = nn.Linear(4 * width_multiplier * 7 * 7, 64 * width_multiplier)\n",
    "        self.output = nn.Linear(64 * width_multiplier, 10)\n",
    "        \n",
    "        def initialize_weights(module: nn.Module):\n",
    "            if module != self:\n",
    "                init.normal(module.weight.data, mean=0.0, std=0.1)\n",
    "        \n",
    "        self.apply(initialize_weights)\n",
    "    \n",
    "    def forward(self, x: autograd.Variable) -> autograd.Variable:\n",
    "        y = functional.max_pool2d(functional.relu(self.conv1(x)), 2)\n",
    "        y = functional.max_pool2d(functional.relu(self.conv2(y)), 2)\n",
    "        y = functional.relu(self.linear(y.view(-1, 4*self.width_multiplier*7*7)))\n",
    "        y = self.output(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "# Now, we test the network to see if it works. \n",
    "net = SimpleCNN(1)\n",
    "print(net(autograd.Variable(torch.rand((2, 1, 28, 28)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import numpy.testing as testing\n",
    "\n",
    "\n",
    "def fsgm(image_batch: torch.FloatTensor,\n",
    "         label_batch: torch.LongTensor,\n",
    "         model: typing.Callable[[autograd.Variable], autograd.Variable],\n",
    "         objective: typing.Callable[[autograd.Variable, autograd.Variable], autograd.Variable],\n",
    "         eps: float):\n",
    "    \"\"\"Takes a batch of images, and modifies each image using the FGSM attack.\"\"\"\n",
    "    for i in range(image_batch.shape[0]):\n",
    "        x = autograd.Variable(torch.unsqueeze(image_batch[i], 0), requires_grad=True)\n",
    "        label = autograd.Variable(label_batch[i:i+1])\n",
    "        output: autograd.Variable = model(x)\n",
    "        loss: autograd.Variable = objective(output, label)\n",
    "        loss.backward()\n",
    "        x.data += eps*torch.sign(x.grad.data)\n",
    "        torch.clamp(x.data, min=0.0, max=1.0, out=x.data)\n",
    "\n",
    "\n",
    "# Now, we test to see there are no obvious errors. \n",
    "def test_fsgm():\n",
    "    net = SimpleCNN(1)\n",
    "    image = torch.zeros((1, 1, 28, 28)) + 0.5\n",
    "    label = torch.LongTensor([2])\n",
    "    perturbed_image = image.clone()\n",
    "    fsgm(perturbed_image, label, net, nn.CrossEntropyLoss(), 0.3)\n",
    "    perturbation = torch.abs(perturbed_image - image)\n",
    "    testing.assert_almost_equal(\n",
    "            perturbation.numpy(),\n",
    "            ((perturbation > 0).float()*0.3).numpy(),\n",
    "            15)\n",
    "\n",
    "\n",
    "def test_fsgm_no_errors_on_cuda():\n",
    "    net = SimpleCNN(1)\n",
    "    net.cuda()\n",
    "    image: torch.FloatTensor = (torch.zeros((1, 1, 28, 28)) + 0.5).cuda()\n",
    "    label = torch.LongTensor([2]).cuda()\n",
    "    perturbed_image: torch.FloatTensor = image.clone()\n",
    "    assert perturbed_image.is_cuda\n",
    "    fsgm(perturbed_image, label, net, nn.CrossEntropyLoss(), 0.3)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    test_fsgm()\n",
    "test_fsgm_no_errors_on_cuda()\n",
    "\n",
    "# What did we learn from this test? How to handle possible zero-gradients. Also, when doing random\n",
    "# initializations, test a few times to make sure that nothing can go wrong with tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(image_batch: torch.FloatTensor,\n",
    "        label_batch: torch.LongTensor,\n",
    "        model: typing.Callable[[autograd.Variable], autograd.Variable],\n",
    "        objective: typing.Callable[[autograd.Variable, autograd.Variable], autograd.Variable],\n",
    "        eps: float,\n",
    "        alpha: float,\n",
    "        num_steps: int,\n",
    "        num_restarts: int):\n",
    "    \"\"\"Runs PGD on the negative of the given loss function with the given parameters on the given image.\"\"\"\n",
    "    \n",
    "    def pgd_without_restarts(sample_index: int):\n",
    "        \"\"\"PGD on negative of the loss function. This has no random restarts.\"\"\"\n",
    "        image = image_batch[sample_index]\n",
    "        x_min = torch.clamp(image - eps, min=0.0)\n",
    "        x_max = torch.clamp(image + eps, max=1.0)\n",
    "        random_perturbation = torch.rand(image.shape)*eps\n",
    "        if image_batch.is_cuda:\n",
    "            random_perturbation = random_perturbation.cuda()\n",
    "        random_start = torch.clamp(image + random_perturbation, min=0.0, max=1.0)\n",
    "        x = autograd.Variable(torch.unsqueeze(random_start, 0), requires_grad=True)\n",
    "        for i in range(num_steps):\n",
    "            output = model(x)\n",
    "            label = autograd.Variable(label_batch[sample_index:sample_index + 1])\n",
    "            loss = objective(output, label)\n",
    "            loss.backward()\n",
    "            x.data += alpha*torch.sign(x.grad.data)\n",
    "            x.data = torch.min(torch.max(x.data, x_min), x_max)\n",
    "            x.grad.data.fill_(0)\n",
    "        return x.data, loss.data[0]\n",
    "    \n",
    "    max_loss = -float(\"inf\")\n",
    "    best_perturbed_image = None\n",
    "    for i in range(image_batch.shape[0]):\n",
    "        for _ in range(num_restarts):\n",
    "            perturbed_image, loss = pgd_without_restarts(i)\n",
    "            if loss > max_loss:\n",
    "                max_loss = loss\n",
    "                best_perturbed_image = perturbed_image\n",
    "        image_batch[i] = best_perturbed_image\n",
    "\n",
    "\n",
    "def test_no_runtime_errors():\n",
    "    net: SimpleCNN = SimpleCNN(1)\n",
    "    image: torch.FloatTensor = torch.rand((2, 1, 28, 28))\n",
    "    label: torch.LongTensor = torch.LongTensor([2, 2])\n",
    "    net.zero_grad()\n",
    "    pgd(image, label, net, nn.CrossEntropyLoss(), 0.3, 0.6, 4, 2)\n",
    "\n",
    "\n",
    "def test_no_runtime_errors_on_cuda():\n",
    "    net: SimpleCNN = SimpleCNN(1)\n",
    "    net.cuda()\n",
    "    image: torch.FloatTensor = torch.rand((2, 1, 28, 28)).cuda()\n",
    "    label: torch.LongTensor = torch.LongTensor([2, 2]).cuda()\n",
    "    net.zero_grad()\n",
    "    pgd(image, label, net, nn.CrossEntropyLoss(), 0.3, 0.6, 4, 2)\n",
    "\n",
    "\n",
    "# A more fine-grained test. We will create a specific linear model and test that the resulting images fall within a\n",
    "# certain range. \n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, label: int):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear: nn.Linear = nn.Linear(1*28*28, 10)\n",
    "        self.linear.weight.data.fill_(0)\n",
    "        self.linear.weight.data[label, :].fill_(1)\n",
    "    \n",
    "    def forward(self, x: autograd.Variable):\n",
    "        y: autograd.Variable = x.view((-1, 1*28*28,))\n",
    "        return y\n",
    "\n",
    "\n",
    "def test_linear_model():\n",
    "    lin = LinearModel(2)\n",
    "    testing.assert_almost_equal(lin.linear.weight.data[0:2, :].numpy(), torch.zeros((2, 28*28)).numpy(), 15)\n",
    "    testing.assert_almost_equal(lin.linear.weight.data[2, :].numpy(), torch.ones((28*28,)).numpy(), 15)\n",
    "    testing.assert_almost_equal(lin.linear.weight.data[3:, :].numpy(), torch.zeros((7, 28*28)).numpy(), 15)\n",
    "\n",
    "\n",
    "def dummy_loss_function(output_batch: autograd.Variable, label_batch: autograd.Variable) -> autograd.Variable:\n",
    "    return -0.5*torch.sum(nn.MSELoss(reduce=False)(output_batch, autograd.Variable(torch.zeros(\n",
    "        output_batch.data.shape))), dim=1)\n",
    "\n",
    "\n",
    "def test_dummy_loss_function():\n",
    "    identity: autograd.Variable = autograd.Variable(torch.eye(2, 10))\n",
    "    expected_result: autograd.Variable = autograd.Variable(-0.5*torch.ones((2,)))\n",
    "    testing.assert_equal(dummy_loss_function(identity, None).data.numpy(), expected_result.data.numpy())\n",
    "\n",
    "\n",
    "def test_single_step_pgd():\n",
    "    image: torch.FloatTensor = torch.zeros(2, 1, 28, 28) + 0.5\n",
    "    labels: torch.LongTensor = torch.LongTensor([2, 2])\n",
    "    perturbed_image: torch.FloatTensor = image.clone()\n",
    "    pgd(perturbed_image, labels, LinearModel(2), dummy_loss_function, 0.3, 1.0, 1, 20)\n",
    "    testing.assert_almost_equal(perturbed_image.numpy(), torch.zeros(image.shape) + 0.2)\n",
    "\n",
    "\n",
    "def test_multistep_pgd():\n",
    "    image: torch.FloatTensor = torch.zeros(2, 1, 28, 28) + 0.5\n",
    "    labels: torch.LongTensor = torch.LongTensor([2, 2])\n",
    "    perturbed_image: torch.FloatTensor = image.clone()\n",
    "    pgd(perturbed_image, labels, LinearModel(2), dummy_loss_function, eps=0.3, alpha=0.01, num_restarts=1, num_steps=10)\n",
    "    \n",
    "    image_min: torch.FloatTensor = torch.clamp(image - 0.3, min=0.0)\n",
    "    \n",
    "    # Calculate image max\n",
    "    image_max: torch.FloatTensor = image + 0.3\n",
    "    for _ in range(10):\n",
    "        image_max = image_max - 0.01*image_max\n",
    "    image_max = torch.max(image_max, image_min)\n",
    "    \n",
    "    testing.assert_array_less(image_min, perturbed_image)\n",
    "    testing.assert_array_less(perturbed_image, image_max)\n",
    "\n",
    "\n",
    "test_no_runtime_errors()\n",
    "test_no_runtime_errors_on_cuda()\n",
    "test_dummy_loss_function()\n",
    "test_linear_model()\n",
    "test_single_step_pgd()\n",
    "test_multistep_pgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n<class 'torch.FloatTensor'>\n<class 'torch.LongTensor'>\n10000\n<class 'torch.FloatTensor'>\n<class 'torch.LongTensor'>\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "label_transform: typing.Callable[[int], torch.LongTensor] = lambda x: torch.LongTensor([x])\n",
    "\n",
    "\n",
    "# Now we need to import MNIST and transform it. \n",
    "training_dataset = datasets.MNIST(\"mnist\", train=True, download=True, transform=image_transform, \n",
    "                                  target_transform=label_transform)\n",
    "testing_dataset = datasets.MNIST(\"mnist\", train=False, download=True, transform=image_transform,\n",
    "                                 target_transform=label_transform)\n",
    "print(len(training_dataset))\n",
    "print(type(training_dataset[0][0]))\n",
    "print(type(training_dataset[0][1]))\n",
    "print(len(testing_dataset))\n",
    "print(type(testing_dataset[0][0]))\n",
    "print(type(testing_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code, I learned the following:\n",
    "* MNIST dataset, without transforms, consists of a list of tuples; each tuple has two elements: a PIL image (28x28) and an integer label (0-9). \n",
    "* The above applies for both the training and testing set. \n",
    "* The target_transform is used to transform the label, while the transform is used to transform the image. \n",
    "\n",
    "Now, we need to concatenate the dataset into one large tensor so that it can be modified with the FGSM and PGD methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f532c860f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f534a77f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "\n",
    "training_images: torch.FloatTensor = torch.zeros((len(training_dataset), 1, 28, 28)).float()\n",
    "training_labels: torch.LongTensor = torch.zeros((len(training_dataset),)).long()\n",
    "testing_images: torch.FloatTensor = torch.zeros((len(training_dataset), 1, 28, 28)).float()\n",
    "testing_labels: torch.LongTensor = torch.zeros((len(training_dataset),)).long()\n",
    "\n",
    "for index, (image, label) in enumerate(training_dataset):\n",
    "    training_images[index] = torch.unsqueeze(image, 0)\n",
    "    training_labels[index:index + 1] = label\n",
    "\n",
    "for index, (image, label) in enumerate(testing_dataset):\n",
    "    testing_images[index] = torch.unsqueeze(image, 0)\n",
    "    testing_labels[index:index + 1] = label\n",
    "\n",
    "pyplot.imshow(training_images[random.randint(0, len(training_images) - 1)].squeeze().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our images and labels as the proper datatypes (FloatTensor size Nx1x28x28 and LongTensor size N, respectively), we can now run FGSM and PGD on each batch. Due to torch's easy semantics for dealing with CUDA, all we need to do is put everything on the GPU and run our experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.001049919000252, 2.002196190000177, 3.003206451000551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0010581020005702, 2.0021059290002086, 3.003054845999941]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import typing\n",
    "\n",
    "\n",
    "class Stopwatch:\n",
    "    \"\"\"\n",
    "    A class that operates a stopwatch. Basic functions include start(), stop(), lap(),\n",
    "    and get_lap_times(). All returned times are in seconds. The accuracy of the stopwatch\n",
    "    is the accuracy of the time.perf_counter() command. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._is_stopped = True\n",
    "        self._last_time: float = 0  # The last time that either start() or lap() was called. \n",
    "        self._current_lap_time: float = 0\n",
    "        self._lap_times: typing.List[float] = []\n",
    "    \n",
    "    def start(self):\n",
    "        if self._is_stopped:\n",
    "            self._last_time = time.perf_counter()\n",
    "            self._is_stopped = False\n",
    "    \n",
    "    def stop(self):\n",
    "        if not self._is_stopped:\n",
    "            current_time = time.perf_counter()\n",
    "            self._current_lap_time += current_time - self._last_time\n",
    "            self._is_stopped = True\n",
    "    \n",
    "    def lap(self):\n",
    "        if not self._is_stopped:\n",
    "            current_time = time.perf_counter()\n",
    "            self._lap_times.append(current_time - self._last_time + self._current_lap_time)\n",
    "            self._last_time = current_time\n",
    "            self._current_lap_time = 0\n",
    "    \n",
    "    def lap_times(self) -> typing.List[float]:\n",
    "        return [t for t in self._lap_times]\n",
    "    \n",
    "    def reset(self):\n",
    "        self._is_stopped = True\n",
    "        self._current_lap_time = 0\n",
    "        self._lap_times = []\n",
    "\n",
    "\n",
    "def run_stopwatch():\n",
    "    # Should print, approximately, '[1, 2, 3]\\n[1, 2, 3]\\n'\n",
    "    s = Stopwatch()\n",
    "    for _ in range(2):\n",
    "        s.start()\n",
    "        time.sleep(1)\n",
    "        s.lap()\n",
    "        time.sleep(1)\n",
    "        s.stop()\n",
    "        time.sleep(1)\n",
    "        s.start()\n",
    "        time.sleep(1)\n",
    "        s.lap()\n",
    "        time.sleep(3)\n",
    "        s.lap()\n",
    "        s.stop()\n",
    "        print(s.lap_times())\n",
    "        s.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss=24.453327178955078, accuracy=0.04, duration=2.500127602000248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [2.500127602000248, 2.432737095000448, 2.378695799000525, 2.361024169999837, 2.368802637999579]\nsetup: [0.00775164000060613, 0.00043373199969209963, 0.005929208999987168, 0.005944301999988966, 0.005837287999383989]\nattack: [2.490778893999959, 2.4309864920005566, 2.3714755950004474, 2.353649265000058, 2.361683899000127]\nforward: [0.00047837999954936095, 0.0003414690008867183, 0.0003465170002527884, 0.0004134620003242162, 0.00039096100044844206]\nbackward: [0.0005620250003630645, 0.0005620550000458024, 0.0005325439997250214, 0.0005207569993217476, 0.00048380599946540315]\nupdate: [0.0004085689997737063, 0.00031210599991027266, 0.0003128460002699285, 0.00036908299989590887, 0.00030489300024783006]\nPGD training vs. FGSM attack: loss=0.0, accuracy=0.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "\n",
    "\n",
    "# Let's generate figure 4!\n",
    "\n",
    "training_images = training_images.cuda()\n",
    "training_labels = training_labels.cuda()\n",
    "testing_images = testing_images.cuda()\n",
    "testing_labels = testing_labels.cuda()\n",
    "\n",
    "\n",
    "def natural(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_simple_cnn(training_attack: str, testing_attack: str, capacity_scale: int,\n",
    "                     batches_between_outputs=10) -> [float, float]:\n",
    "    \"\"\"\n",
    "    Trains an instance of SimpleCNN with the given capcity scale on training images, which were perturbed via \n",
    "    training_attack, and then tests the resulting model on testing images, which were perturbed via testing_attack.\n",
    "    Note that perturbations on the training images are recomputed for each batch, since the attacks depend on the\n",
    "    state of the current model instance. The accuracy (and loss) of the model on the test images is returned. \n",
    "    \n",
    "    This method is used to generate a single point on one of the plots in the top half of Figure 4. \n",
    "    \n",
    "    :param training_attack: One of {'natural', 'fgsm', 'pgd'}.\n",
    "    :param testing_attack: One of {'natural', 'fgsm', 'pgd'},\n",
    "    :param capacity_scale: One of {1, 2, 4, 8, 16}. \n",
    "    :return: The accuracy and loss of the trained model on the test set. \n",
    "    \"\"\"\n",
    "    \n",
    "    net = SimpleCNN(capacity_scale)\n",
    "    net.cuda()\n",
    "    \n",
    "    def get_attack_function(name: str) -> typing.Callable[[torch.FloatTensor, torch.LongTensor], None]:\n",
    "        if name == 'natural':\n",
    "            return natural\n",
    "        elif name == 'fgsm':\n",
    "            return functools.partial(fsgm, model=net, objective=nn.CrossEntropyLoss(), eps=0.3)\n",
    "        elif name == 'pgd':\n",
    "            return functools.partial(pgd, model=net, objective=nn.CrossEntropyLoss(), eps=0.3, alpha=0.01,\n",
    "                                     num_steps=40, num_restarts=1)\n",
    "    \n",
    "    training_attack = get_attack_function(training_attack)\n",
    "    testing_attack = get_attack_function(testing_attack)\n",
    "    \n",
    "    shuffled_indexes = torch.randperm(len(training_images)).cuda()\n",
    "    shuffled_training_images = training_images[shuffled_indexes]\n",
    "    shuffled_training_labels = training_labels[shuffled_indexes]\n",
    "    \n",
    "    stopwatches: typing.DefaultDict[str, Stopwatch] = collections.defaultdict(Stopwatch)\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "    batch_start_index = 0\n",
    "    batch_size = 50\n",
    "    num_steps = 5\n",
    "    for step in range(num_steps):\n",
    "        stopwatches['step'].start()\n",
    "        \n",
    "        stopwatches['setup'].start()\n",
    "        batch_shape = (batch_size,) + training_images[0, :, :, :].shape\n",
    "        batch_images: torch.FloatTensor = torch.zeros(batch_shape).float().cuda()\n",
    "        batch_labels: torch.LongTensor = torch.zeros((batch_size,)).long().cuda()\n",
    "        batch_images.copy_(shuffled_training_images[batch_start_index:batch_start_index + batch_size])\n",
    "        batch_labels.copy_(shuffled_training_labels[batch_start_index:batch_start_index + batch_size])\n",
    "        stopwatches['setup'].lap()\n",
    "        stopwatches['setup'].stop()\n",
    "        \n",
    "        stopwatches['attack'].start()\n",
    "        training_attack(batch_images, batch_labels)\n",
    "        stopwatches['attack'].lap()\n",
    "        stopwatches['attack'].stop()\n",
    "        \n",
    "        stopwatches['forward'].start()\n",
    "        output = net(autograd.Variable(batch_images))\n",
    "        stopwatches['forward'].lap()\n",
    "        stopwatches['forward'].stop()\n",
    "        \n",
    "        loss: autograd.Variable = functional.cross_entropy(output, autograd.Variable(batch_labels))\n",
    "        net.zero_grad()\n",
    "        \n",
    "        stopwatches['backward'].start()\n",
    "        loss.backward()\n",
    "        stopwatches['backward'].lap()\n",
    "        stopwatches['backward'].stop()\n",
    "        \n",
    "        stopwatches['update'].start()\n",
    "        optimizer.step()\n",
    "        stopwatches['update'].lap()\n",
    "        stopwatches['update'].stop()\n",
    "        \n",
    "        stopwatches['step'].lap()\n",
    "        stopwatches['step'].stop()\n",
    "        if step % batches_between_outputs == 0:\n",
    "            _, predictions = torch.max(output.data, 1)\n",
    "            fraction_correct = float((predictions == batch_labels).sum())/batch_size\n",
    "            print(\n",
    "                'Step {0}: loss={1}, accuracy={2}, duration={3}'.format(\n",
    "                    str(step), str(loss.data[0]), str(fraction_correct), str(stopwatches['step'].lap_times()[-1])))\n",
    "        \n",
    "        # OH MY GOD\n",
    "        # I SPENT A WEEK WRITING THIS\n",
    "        # AND I FORGOT TO INCREMENT THE BATCH INDEX\n",
    "        # NO WONDER THE PERFORMANCE SUCKED\n",
    "        \n",
    "        batch_start_index = (batch_start_index + batch_size) % len(training_images)\n",
    "    \n",
    "    for name, stopwatch in stopwatches.items():\n",
    "        print(name + \": \" + str(stopwatch.lap_times()))\n",
    "    return 0.0, 0.0\n",
    "    \n",
    "    testing_batch_size = 100  # Must divide len(testing_images).\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch_index in range(int(len(testing_images)/testing_batch_size)):\n",
    "        batch_images: torch.FloatTensor = torch.zeros(\n",
    "            (testing_batch_size,) + testing_images[0, :, :, :].shape).float().cuda()\n",
    "        batch_labels: torch.LongTensor = torch.zeros((testing_batch_size,)).long().cuda()\n",
    "        batch_images.copy_(testing_images[batch_index * testing_batch_size:(batch_index + 1)*testing_batch_size])\n",
    "        batch_labels.copy_(testing_labels[batch_index * testing_batch_size:(batch_index + 1)*testing_batch_size])\n",
    "        testing_attack(batch_images, batch_labels)\n",
    "        output: autograd.Variable = net(autograd.Variable(batch_images))\n",
    "        loss: autograd.Variable = functional.cross_entropy(output, autograd.Variable(batch_labels), size_average=False)\n",
    "        _, predictions = torch.max(output.data, 1)\n",
    "        total_correct += (predictions == batch_labels).sum()\n",
    "        total_loss += loss.data[0]\n",
    "        num_samples += testing_batch_size\n",
    "    \n",
    "    return total_loss/num_samples, float(total_correct)/num_samples\n",
    "\n",
    "\n",
    "# For our sanity check, we want to train the network on PGD and test it on FGSM; the accuracy should be about 95.6%. \n",
    "loss, accuracy = train_simple_cnn('pgd', 'fgsm', 16)\n",
    "print('PGD training vs. FGSM attack: loss={0}, accuracy={1}'.format(loss, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
